{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radicalz1/colabs/blob/main/2_Fooocus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#@title # ðŸ‘ˆ **Fooocus**\n",
        "#@markdown [project sourse](https://github.com/lllyasviel/Fooocus), [other notebooks](https://www.patreon.com/marat_ai)\n",
        "\n",
        "#@markdown _MidJorney inspired UI for Stable Diffusion_\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install pygit2==1.12.2\n",
        "clear_output()\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "clear_output()\n",
        "\n",
        "# !python entry_with_update.py --share --always-offload-from-vram --always-gpu\n",
        "# !python launch.py --share  --always-offload-from-vram --always-gpu --preset realistic\n",
        "!python launch.py --share  --always-high-vram --disable-offload-from-vram --preset realistic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv3Vysw7QpR4",
        "outputId": "2eaba712-6249-4eb3-aa2a-5b6bade73da0",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram', '--preset', 'realistic']\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Fooocus version: 2.3.1\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "2024-04-13 18:08:13.368270: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-13 18:08:13.368324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-13 18:08:13.498487: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-13 18:08:16.070257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Refiner unloaded.\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://2ce90338da4f510cb0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "Request to load LoRAs [['SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors', 0.25], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 788 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.01 seconds\n",
            "Started worker with PID 8433\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://2ce90338da4f510cb0.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 3859607441051559137\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "extra clip vision: ['vision_model.embeddings.position_ids']\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['conditioner.embedders.0.logit_scale', 'conditioner.embedders.0.text_projection'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.63 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.33 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 64.21 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.21 seconds\n",
            "100% 60/60 [00:57<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "Calculating sha256 for /content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors: 7263d2b958d12040646a68b06754e68dd7a7a4865560345b5833c50216eef10c\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 98.70 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "100% 60/60 [00:57<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 60.32 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 223.32 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.99 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 5909661601752433658\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['conditioner.embedders.0.logit_scale', 'conditioner.embedders.0.text_projection'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.68 seconds\n",
            "Refiner model loaded: /content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.logit_scale', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v9Rundiffusionphoto2.safetensors\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/juggernautXL_v9Rundiffusionphoto2.safetensors].\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.18 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.57 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 77.57 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.41 seconds\n",
            " 50% 30/60 [00:29<00:29,  1.00it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:57<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "Calculating sha256 for /content/Fooocus/models/checkpoints/juggernautXL_v9Rundiffusionphoto2.safetensors: c9e3e68f89b8e38689e1097d4be4573cf308de4e3fd044c64ca697bdb4aa8bca\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 104.14 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            " 50% 30/60 [00:28<00:29,  1.01it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:57<00:00,  1.05it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 60.35 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 242.12 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.94 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 2126725380825425553\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 57\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.23 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.33 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            " 95% 57/60 [00:55<00:02,  1.07it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 61.50 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            " 95% 57/60 [00:53<00:02,  1.05it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 59.86 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 127.77 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.07 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 6593113713835468877\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 51\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.26 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.58 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.35 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            " 85% 51/60 [00:49<00:08,  1.06it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 61.52 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            " 85% 51/60 [00:47<00:08,  1.05it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.20 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 60.10 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 128.04 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.93 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 5078272573012866622\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 42\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.25 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.31 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.29 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            " 70% 42/60 [00:40<00:17,  1.02it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            " 80% 48/60 [00:47<00:11,  1.00it/s]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 54.58 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 603389597053743843\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 42\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.19 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.52 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.19 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "100% 60/60 [00:57<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 60.90 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 67.13 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 603389597053743843\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 42\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['conditioner.embedders.0.logit_scale', 'conditioner.embedders.0.text_projection'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.53 seconds\n",
            "Refiner model loaded: /content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.21 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.12 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.57 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 39.95 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            " 70% 42/60 [00:41<00:17,  1.03it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:58<00:00,  1.02it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 61.88 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 101.86 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.88 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 603389597053743843\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:06<00:00, 146MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 42\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.27 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.62 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 20.39 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            " 70% 42/60 [00:41<00:17,  1.04it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:58<00:00,  1.02it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 62.30 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 82.74 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.97 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 603389597053743843\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 42\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.logit_scale', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.35 seconds\n",
            "Refiner model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v9Rundiffusionphoto2.safetensors\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['conditioner.embedders.0.logit_scale', 'conditioner.embedders.0.text_projection'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/epicrealismXL_v5Ultimate.safetensors].\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/juggernautXL_v9Rundiffusionphoto2.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.32 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.58 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 85.49 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            " 70% 42/60 [00:40<00:17,  1.05it/s]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Refiner Swapped\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2024-04-13/log.html\n",
            "Generating and saving time: 61.17 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 146.68 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.85 seconds\n"
          ]
        }
      ],
      "source": [
        "#@title **RUN**\n",
        "# entry_with_update.py  [-h] [--listen [IP]] [--port PORT]\n",
        "#                       [--disable-header-check [ORIGIN]]\n",
        "#                       [--web-upload-size WEB_UPLOAD_SIZE]\n",
        "#                       [--external-working-path PATH [PATH ...]]\n",
        "#                       [--output-path OUTPUT_PATH] [--temp-path TEMP_PATH]\n",
        "#                       [--cache-path CACHE_PATH] [--in-browser]\n",
        "#                       [--disable-in-browser] [--gpu-device-id DEVICE_ID]\n",
        "#                       [--async-cuda-allocation | --disable-async-cuda-allocation]\n",
        "#                       [--disable-attention-upcast] [--all-in-fp32 | --all-in-fp16]\n",
        "#                       [--unet-in-bf16 | --unet-in-fp16 | --unet-in-fp8-e4m3fn | --unet-in-fp8-e5m2]\n",
        "#                       [--vae-in-fp16 | --vae-in-fp32 | --vae-in-bf16]\n",
        "#                       [--clip-in-fp8-e4m3fn | --clip-in-fp8-e5m2 | --clip-in-fp16 | --clip-in-fp32]\n",
        "#                       [--directml [DIRECTML_DEVICE]] [--disable-ipex-hijack]\n",
        "#                       [--preview-option [none,auto,fast,taesd]]\n",
        "#                       [--attention-split | --attention-quad | --attention-pytorch]\n",
        "#                       [--disable-xformers]\n",
        "#                       [--always-gpu | --always-high-vram | --always-normal-vram |\n",
        "#                        --always-low-vram | --always-no-vram | --always-cpu]\n",
        "#                       [--always-offload-from-vram] [--disable-server-log]\n",
        "#                       [--debug-mode] [--is-windows-embedded-python]\n",
        "#                       [--disable-server-info] [--share] [--preset PRESET]\n",
        "#                       [--language LANGUAGE] [--disable-offload-from-vram]\n",
        "#                       [--theme THEME] [--disable-image-log]\n",
        "\n",
        "# !python entry_with_update.py --share --always-offload-from-vram --always-gpu\n",
        "# !python launch.py --share  --always-offload-from-vram --always-gpu --preset realistic\n",
        "!python launch.py --share  --always-high-vram --disable-offload-from-vram --preset realistic\n",
        "clear_output()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}